![image](https://github.com/wenjtop/Multiple-Object-Tracking-system/assets/84707983/71252970-1583-485d-bf86-1f11ba967d92)# Multiple-Object-Tracking-system
系统支持：多目标实时跟踪，上传视频跟踪、视频管理、目标计数、跟踪截图报告、跟踪结果下载、远程域名访问。 多目标跟踪算法检测部分是：YOLOv8。数据关联部分：重新设计的一个算法。系统框架：Django。系统做了内网穿透支持远程域名访问。视频实时推流：重新写了一个视频推流方法，延迟能做到300ms左右，基本能满足实时跟踪，偶尔会出现掉帧现象。



(1) 采用最新的YOLOv8作为多目标跟踪的检测器，并重新设计了一种多目标跟踪的数据关联算法，命名为EnhanceSort。该算法主要思想是保留中高分检测框，并将它们与正在跟踪的轨迹、新建立的轨迹和丢失的轨迹依次进行匹配，形成更有效的匹配策略。其中，引入中分检测框与轨迹相关联，可以恢复正确检测的中分检测框并过滤背景。在轨迹预测中，将卡尔曼滤波的状态表示从XYAH（中心坐标X、中心坐标Y、高宽比A、高度H）改为XYWH（中心坐标X、中心坐标Y、宽度W、高度H），有助于简化跟踪过程并使目标的空间尺寸更直观易懂。这可以减少计算过程中产生的误差和冗余，同时提高算法的计算效率和跟踪准确性，为多目标跟踪算法的优化提供帮助。在衡量轨迹预测框与检测框距离时，使用GIOU替代IOU作为相似度度量。GIOU考虑了目标边界框之间的几何关系，包括宽高比和相对位置，从而在目标跟踪中提供更准确的匹配信息。这提高了跟踪算法在处理遮挡、目标间交互等复杂场景时的准确性和鲁棒性，特别是在处理复杂场景和遮挡问题时具有显著优势。
(2) 本文重新设计了一种多目标检测跟踪的特征重识别算法，命名为LNG-Transformer。该算法的每个网络模块都融合了局部信息、邻域信息和全局信息的交互。在网络的任何时期，该算法都能够学习到局部信息和全局信息。从而能够有效地提取目标的深层特征，实现更为精确的目标关联。
(3) 设计了多目标跟踪系统，该系统包括用户注册、登录及用户信息管理模块，摄像头实时多目标跟踪模块和数据管理模块。为计算机视觉、智能安全监控和商业客流分析等领域提供了有效的解决方案。


3.3.1 EnhanceSort算法结构设计
本小节提出了一种简单、有效、通用的轨迹关联方法，命名为EnhanceSort。 与以往Sort、DeepSort、FairMOT等网络只保留高分检测框不同，借鉴byteTrack的思想，保留更多的检测框，然后再依次和正在被跟踪的轨迹、新建立的轨迹、丢失的轨迹进行匹配。算法结构如图3-7所示。
 
图3-7  EnhanceSort算法结构
首先将YOLOv8检测到的目标框以置信度为标准，分为低分检测框、中分检测框和高分检测框。合并中分检测框和高分检测框为中高检测框，去掉所有的低分检测框，使得大部分的检测框都得到了保留。其中中分检测框通常是目标发生在遮挡、运动模糊或大小变化发生时，引入中分检测框与轨迹相关联，可以恢复正确检测的中分检测框，过滤背景。
同时将轨道也分为三组，正在被跟踪的轨迹，新建立的轨迹，丢失的轨迹。正在被跟踪的轨迹表示当前轨迹是一个稳定的轨迹，能匹配到正确的检测框。新建立的轨迹表示当前轨迹只出现了一次，还没有进行第二次匹配检测框，如果第二次匹配检测框成功就转换为正在被跟踪的轨迹，否者直接丢弃，因为很有可能是误得到不稳定检测框，所以直接去掉。丢失的轨迹表示当前轨轨迹没有匹配检测框成功，是由正在被跟踪的轨迹匹配检测框失败转换形成的。
		然后如图3-7示整个流程是中高检测框依次和正在被跟踪的轨迹，新建立的轨迹，丢失的轨迹进行三次匹配。第一次匹配是中高检测框与正在被跟踪的轨迹进行匹配，先采用卡尔曼滤波来预测正在被跟踪的轨迹中每个轨道在当前帧中的新位置，再与中高检测框进行匹配。匹配后会得到三部分，未匹配成功的轨迹，未匹配成功的检测框和匹配成功的轨迹。未匹配成功的轨迹为会直接转换成丢失的轨迹，在下一帧中被分配到丢失的轨迹组中进行匹配。未匹配成功的检测框会在下一次匹配中与新建立的轨迹组进行匹配。匹配成功的轨迹会转换成正在被跟踪的轨迹，并且更新轨迹的卡尔曼参数，在下一帧中被分配到正在被跟踪的轨迹组中进行匹配。
		第二次匹配是第一次未匹配成功的检测框与新建立的轨迹进行匹配，与第一次匹配不同，新建里的轨道只是对轨道的卡尔曼滤波参数做了初始化，还无法形成有效的轨迹预测，所以不进行卡尔曼的预测，直接进行匹配。与第一次相同匹配后会得到三部分，未匹配成功的轨迹，未匹配成功的检测框和匹配成功的轨迹。未匹配成功的轨迹可能是上一帧误检所导致，所以直接丢弃，能有效的规避背景误检。未匹配成功的检测框会在下一次匹配中与丢失的轨迹组进行匹配。匹配成功的轨迹会转换成正在被跟踪的轨迹，并且更新轨迹的卡尔曼参数，在下一帧中被分配到正在被跟踪的轨迹组中进行匹配。
		第三次匹配是第二次未匹配成功的检测框与丢失的轨迹进行匹配，先采用卡尔曼滤波来预测正在被跟踪的轨迹中每个轨道在当前帧中的新位置，再与未匹配成功的检测框进行匹配。匹配后会得到三部分，未匹配成功的轨迹，未匹配成功的检测框和匹配成功的轨迹。未匹配成功的轨迹会判断是否超过丢失帧的阈值，如果超过就直接丢弃，否者继续在下一帧中被分配到丢失的轨迹组中进行匹配。未匹配成功的检测框会判断置信度分数是否超过阈值，如果是就建立新的轨迹，在下一次分配到新建立的轨迹组进行匹配，否者就丢弃。匹配成功的轨迹会转换成正在被跟踪的轨迹，并且更新轨迹的卡尔曼参数，在下一帧中被分配到正在被跟踪的轨迹组中进行匹配。
		以上就是数据关联的整个过程。在Sort、DeepSort和ByteTrack等算法中，通常新建立的轨迹也会进行卡尔曼滤波预测再进行匹配，但新建立的轨迹的卡尔曼滤波参数并没有得到有效的学习，直接进行预测反而会产生误差。所以本文直接将新建的轨迹单独进行匹配，以实现更高的精度。
算法 1: EnhanceSort的伪代码.
Input: 视频序列 V; 目标检测器 Det; 检测评分阈值τ; 新轨道评分阈值ρ;
Output: 视频序列跟踪轨迹T_tracked
	 Initialization: T_tracked ← ∅; T_new ← ∅; T_lost ← ∅
	 for frame f_k in V do
	/* 预测检测框和分数 */
		D_(middle-high) ← ∅
		D_k ← Det(f_k)
		for d in D_k do
			If d.score > τ then
			  	D_(middle-high) ← D_(middle-high) ∪ {d}
			end
		end
	/* 预测正在被跟踪的轨迹新位置*/
		for t in T_tracked+ T_lost do
			t ← KalmanFilter(t)
		  end
	/* 第一次数据关联*/
		  Associate T_tracked and D_(middle-high) using  Similarity#1
		  D_remain ← remaining object boxes from D_(middle-high)
		T_tracked ← Associate success T_tracked
		T_(tmp-lost) ← Associate fail T_tracked
	/* 第二次数据关联*/
		Associate T_new and D_remain using  Similarity#1
		D_(re-remain) ← remaining object boxes from D_remain
		T_tracked ← Associate success T_new
	/* 第三次数据关联*/
		Associate T_lost and D_(re-remain) using  Similarity#1
		T_new ← remaining object boxes from D_remain and score > ρ
		T_tracked ← Associate success T_lost
		T_lost ← Associate fail T_lost and time < 30
		T_lost ←T_(tmp-lost)
	 end
	 Return T_tracked
		EnhanceSort的输入是一个视频序列V，对象检测器YOLOv8，检测分数最低阈值τ，还有新建立轨道的阈值。EnhanceSort的输出是视频的跟踪轨道Τ，每个轨道包含了每一帧中对象的检测框和ID标识。对于视频中每一帧图像，使用检测器YOLOv8来预测检测框和分数。根据检测分数阈值τ，筛选出中高分数目标框，低于阈值的目标框直接去掉，在算法1中的第3行到第9行实现。在第一次匹配前，使用卡尔曼滤波来预测T_tracked和T_lost中每个轨道在当前帧的新位置，在算法1中的第10行到第12行实现。
		第一次关联是在D_(middle-high)和所有正在被跟踪的轨迹T_tracked之间。Similarity #1是计算所有检测框D_(middle-high)和所有轨道T_tracked的两两之间的IoU距离，然后采用匈牙利算法进行相似度匹配。将不匹配的检测框保留在在D_remain中，不匹配的轨道保留在T_(tmp-lost)中，在算法1的第13 - 16行实现。
		第二次关联是新建立的轨迹T_new和第一次关联后剩余的D_remain之间进行的。 Similarity #1与第一次类似，是计算所有检测框D_(middle-high)和所有轨道T_tracked的两两之间的IoU距离，然后采用匈牙利算法进行相似度匹配。不同之处通常会设置一个更低的匹配评分阈值，因为新建立的轨迹，还无法进行卡尔曼滤波预测当前帧，设置的评测阈值太高，容易导致与正确的检测框匹配失败。将不匹配的检测框保留在在D_(re-remain)中，不匹配的轨道直接删掉，这很有可能是上一帧误检导致建立的新轨迹(算法1的第17 - 19行)。
		第三次关联是新建立的轨迹T_lost和第二次关联后剩余的D_(re-remain)之间进行的。关联完成后，对于未匹配成功的轨迹，对于T_lost中的每个轨迹，只有当它存在超过30帧时，就轨迹中删除它。否则，继续保留轨迹在T_lost列表中。最后从第三次关联中筛选出高分检测框初始化新的轨迹，删掉未匹配的笛梵检测框，因为低分检测框通常包含严重的遮挡或运动模糊，外观特征不可靠。可有效的筛选出背景。最后输出T_tracked，里面包含了视频V里面所有目标框和ID标识，在算法1的第20 - 26行实现。
		为了提高多目标检测的性能，使用高性能探测器YOLOv8与该数据关联方法相结合，其中，选择中高分检测框，依次和正在跟踪的轨迹、新建立的轨迹和丢失的轨迹进行匹配。其中中分检测框通常是目标发生在遮挡、运动模糊或大小变化发生时，引入中分检测框与轨迹相关联，可以恢复正确检测的中分检测框，过滤背景。数据关联算法EnhanceSort整体结构简单，通过对轨迹进行分组，从而进行更有效的匹配。
![image](https://github.com/wenjtop/Multiple-Object-Tracking-system/assets/84707983/71a27299-1e15-4a58-afee-43889ae8a6c9)

